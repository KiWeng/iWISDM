{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating, saving, and loading an individual task"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## iWISDM+:\n",
    "\n",
    "1. Memory: task difficulty is varied by changing the number of delay frames\n",
    "a. 1frame tasks: report of object property after delay (location or category)\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/memory_1_frame' --trials_dir='temp/memory_1_frame' --config_path='configs/single_frame_cat.json' --min_len=1 --max_len=10 --n_trials=10 --n_tasks=20 --features='cat' --min_joint_ops=0 --max_joint_ops=0 --max_delay=10 --force_balance\n",
    "```\n",
    "b. 2frame tasks: compare two object properties with delay either in between or afterward (location, category,\n",
    "identity)\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/memory_2_frame' --trials_dir='temp/memory_2_frame' --config_path='configs/low_complexity_cat.json' --min_len=3 --max_len=10 --n_trials=10 --n_tasks=10 --features='cat' --min_joint_ops=0 --max_joint_ops=0 --max_delay=10 --force_balance\n",
    "```\n",
    "*the max_joint_ops may should be set to 0 to avoid and, or in the instructions*\n",
    "2. Object localization:\n",
    "a. 1frame: report location\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/localization_1_frame' --trials_dir='temp/localization_1_frame' --config_path='configs/high_complexity_loc_noswitch.json' --min_len=1 --max_len=1 --n_trials=100 --n_tasks=10 --features='loc' --min_joint_ops=0 --max_joint_ops=0 --non_bool_actions\n",
    "```\n",
    "b. 2frames: comparison based on location\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/localization_2_frame' --trials_dir='temp/localization_2_frame' --config_path='configs/low_complexity_loc.json' --min_len=2 --max_len=2 --n_trials=10 --n_tasks=1 --features='loc' --min_joint_ops=0 --max_joint_ops=1 --force_balance\n",
    "```\n",
    "3. Object categorization: similar to above but based on category\n",
    "a. 1frame: report category\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/categorization_1_frame' --trials_dir='temp/categorization_1_frame' --config_path='configs/single_frame_cat.json' --min_len=1 --max_len=1 --n_trials=10 --n_tasks=10 --features='cat' --min_joint_ops=0 --max_joint_ops=0 --force_balance\n",
    "```\n",
    "b. 2frames: comparison based on category\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/categorization_2_frame' --trials_dir='temp/categorization_2_frame' --config_path='configs/low_complexity_cat.json' --min_len=2 --max_len=2 --n_trials=10 --n_tasks=10 --features='cat' --min_joint_ops=0 --max_joint_ops=1 --force_balance\n",
    "```\n",
    "4. Spatial attention:\n",
    "a. 1frame with distractor. Report object category\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/spatial_attn_1_frame' --trials_dir='temp/spatial_attn_1_frame' --config_path='configs/single_frame_cat.json' --min_len=1 --max_len=1 --n_trials=10 --n_tasks=10 --features='cat' --min_joint_ops=0 --max_joint_ops=0 --force_balance --n_distractor_frame=1\n",
    "```\n",
    "b. 2frame tasks with distractors on both. The tasks are based on category (or identity) information, so objects are\n",
    "identified by their location information where instruction specifies which object on each frame is to be attended to\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/spatial_attn_2_frame' --trials_dir='temp/spatial_attn_2_frame' --config_path='configs/low_complexity_cat.json' --min_len=2 --max_len=2 --n_trials=10 --n_tasks=10 --features='cat' --min_joint_ops=0 --max_joint_ops=1 --force_balance --n_distractor_frame=2\n",
    "```\n",
    "5. Feature attention: similar to above but the tasks are based on location information, so objects are identified by\n",
    "their category information\n",
    "a. 1 frame\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/feature_attn_1_frame' --trials_dir='temp/feature_attn_1_frame' --config_path='configs/single_frame_loc.json' --min_len=1 --max_len=1 --n_trials=10 --n_tasks=10 --features='loc' --min_joint_ops=0 --max_joint_ops=0 --force_balance --n_distractor_frame=1\n",
    "```\n",
    "b. 2 frame\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/feature_attn_2_frame' --trials_dir='temp/feature_attn_2_frame' --config_path='configs/low_complexity_loc.json' --min_len=2 --max_len=2 --n_trials=10 --n_tasks=10 --features='loc' --min_joint_ops=0 --max_joint_ops=1 --force_balance --n_distractor_frame=2\n",
    "```\n",
    "6. Temporal attention: 2 frames or more.\n",
    "a. 1frame decisions: report of object property (location or category) when there are other distractor frames\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/temporal_attn_1_frame_cat' --trials_dir='temp/temporal_attn_1_frame_cat' --config_path='configs/single_frame_cat.json' --min_len=2 --max_len=2 --n_trials=10 --n_tasks=10 --features='cat' --min_joint_ops=0 --max_joint_ops=0 --force_balance --n_distractor_time=1\n",
    "```\n",
    "b. 2frame decisions: comparison between two objects when there are other distractor frames (location, category,\n",
    "                                                                                            identity)\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/temporal_attn_2_frame_cat' --trials_dir='temp/temporal_attn_2_frame_cat' --config_path='configs/low_complexity_cat.json' --min_len=6 --max_len=10 --n_trials=10 --n_tasks=10 --features='cat' --min_joint_ops=0 --max_joint_ops=1 --force_balance --n_distractor_time=2\n",
    "```\n",
    "7. Logical reasoning: similar to main iwisdm assessments where we generate random tasks and categorize them to levels of\n",
    "complexity according to factors such as number of frames, number of operations, number of switches etc (refer to\n",
    "iwisdm paper)\n",
    "(probably version with image&without image\n",
    "```shell\n",
    "conda activate iwisdm\n",
    "python create_bench.py --stim_dir='../data/shapenet_handpicked' --tasks_dir='./tasks/logical' --trials_dir='temp/logical' --config_path='configs/high_complexity_all.json' --min_len=9 --max_len=9 --n_trials=10 --n_tasks=10 --features='all' --min_joint_ops=1 --max_joint_ops=2 --force_balance --non_bool_actions\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from wisdom import make\n",
    "from wisdom.envs.shapenet.task_generator import TemporalTask\n",
    "import wisdom.envs.shapenet.registration as env_reg\n",
    "\n",
    "from wisdom import read_write\n",
    "import wisdom.envs.shapenet.task_generator as tg\n",
    "\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "n_tasks = 100  # number of tasks to be generated\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "stim_dir = '../data/shapenet_handpicked'\n",
    "\n",
    "# Create environment\n",
    "env = make(\n",
    "    env_id='ShapeNet',\n",
    "    dataset_fp=stim_dir\n",
    ")\n",
    "\n",
    "# Initialize environment\n",
    "print(env.env_spec.auto_gen_config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_task_info(task_type, trial):\n",
    "    images = []\n",
    "\n",
    "    for img_path in sorted(glob.glob(f'outputs/{task_type}/trials/train/trial{trial}/frames/*.png')):\n",
    "        images.append(mpimg.imread(img_path))\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    columns = 10\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(len(images) // columns + 1, columns, i + 1)\n",
    "        plt.imshow(image)\n",
    "\n",
    "    with open(f'outputs/{task_type}/trials/train/trial{trial}/frames/task_info.json') as f:\n",
    "        trial_info = json.load(f)\n",
    "\n",
    "    print('instruction ', trial_info['instruction'])\n",
    "    print('answers: ', trial_info['answers'])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Task Creation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Here we create a task where the goal is to correctly compare the locations of two stimuli (objects)\n",
    "    - We use the TemporalTask class as a parent class to build from. (All custom tasks must inherit from this TemporalTask)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Memory 1 Frame"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Base1FrameTask(TemporalTask):\n",
    "    \"\"\"\n",
    "    Compare objects on chosen frames are of the same location or not.\n",
    "    @param: whens: a list of two frame names to compare stimuli location between\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, whens, op=None, first_shareable=None):\n",
    "        # Initialize Class with parent class\n",
    "        super(Base1FrameTask, self).__init__(whens=whens, first_shareable=first_shareable)\n",
    "\n",
    "        # Get the whens\n",
    "        when = self.whens[0]\n",
    "\n",
    "        # Select the specified frames\n",
    "        objs = tg.Select(when=when)\n",
    "\n",
    "        # Set operator to check if they're the same location\n",
    "        self._operator = op(objs)\n",
    "\n",
    "        # Set the number of frames\n",
    "        self.n_frames = env_reg.compare_when([when]) + 1\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Base2FrameTask(TemporalTask):\n",
    "    \"\"\"\n",
    "    Compare objects on chosen frames are of the same location or not.\n",
    "    @param: whens: a list of two frame names to compare stimuli location between\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, whens, op=None, first_shareable=None, ):\n",
    "        # Initialize Class with parent class\n",
    "        super(Base2FrameTask, self).__init__(whens=whens, first_shareable=first_shareable)\n",
    "\n",
    "        # Get the whens\n",
    "        when1, when2 = self.whens[0], self.whens[1]\n",
    "\n",
    "        # Select the specified frames\n",
    "        objs1 = tg.Select(when=when1)\n",
    "        objs2 = tg.Select(when=when2)\n",
    "\n",
    "        # Get the locations of stimuli within each frame\n",
    "        a1 = op(objs1)\n",
    "        a2 = op(objs2)\n",
    "\n",
    "        # Set operator to check if they're the same location\n",
    "        self._operator = tg.IsSame(a1, a2)\n",
    "\n",
    "        # Set the number of frames\n",
    "        self.n_frames = env_reg.compare_when([when1, when2]) + 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for op, name_op in zip([tg.GetLoc, tg.GetCategory], ['loc', 'cat']):\n",
    "    for n_delays in range(1, 6):\n",
    "        whens_1 = [f'last{n_delays}']\n",
    "        whens_2 = [f'last{n_delays}', 'last0']\n",
    "        memory_1_frame_task = Base1FrameTask(whens_1, op)\n",
    "        memory_2_frame_task = Base2FrameTask(whens_2, op)\n",
    "        task_type_1 = f\"memory1frame_{n_delays}_{name_op}\"\n",
    "        task_type_2 = f\"memory2frame_{n_delays}_{name_op}\"\n",
    "        read_write.write_task(memory_1_frame_task, f'outputs/tasks/{task_type_1}.json')\n",
    "        read_write.write_task(memory_2_frame_task, f'outputs/tasks/{task_type_2}.json')\n",
    "\n",
    "        for i in range(n_tasks):\n",
    "            # Generate trial info\n",
    "            trials_1 = env.generate_trials(tasks=[memory_1_frame_task], mode='train')\n",
    "            trials_2 = env.generate_trials(tasks=[memory_2_frame_task], mode='train')\n",
    "            imgs_1, _, info_dict_1 = trials_1[0]\n",
    "            imgs_2, _, info_dict_2 = trials_2[0]\n",
    "\n",
    "            # Write trial to disk\n",
    "            read_write.write_trial(imgs_1, info_dict_1, f'outputs/{task_type_1}/trials/train' + f'/trial{i}')\n",
    "            read_write.write_trial(imgs_2, info_dict_2, f'outputs/{task_type_2}/trials/train' + f'/trial{i}')\n",
    "\n",
    "        show_task_info(task_type_1, 0)\n",
    "        show_task_info(task_type_2, 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Object Localization 1 Frame"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whens = ['last0']\n",
    "obj_loc_1_frame = Base1FrameTask(whens, tg.GetLoc)\n",
    "task_type = \"obj_loc_1_frame \"\n",
    "\n",
    "read_write.write_task(obj_loc_1_frame, f'outputs/tasks/{task_type}')\n",
    "G = obj_loc_1_frame.to_graph()\n",
    "obj_loc_1_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(f'outputs/tasks/{task_type}.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(n_tasks):\n",
    "    # Generate trial info\n",
    "    trials = env.generate_trials(tasks=[obj_loc_1_frame], mode='train')\n",
    "    imgs, _, info_dict = trials[0]\n",
    "\n",
    "    # Write trial to disk\n",
    "    read_write.write_trial(imgs, info_dict, f'outputs/{task_type}/trials/train' + f'/trial{i}')\n",
    "\n",
    "show_task_info(task_type, 0)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Obj Loc 2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whens = ['last0', 'last1']\n",
    "obj_loc_2_frame = Base2FrameTask(whens, tg.GetLoc)\n",
    "task_type = \"obj_loc_2_frame \"\n",
    "\n",
    "read_write.write_task(obj_loc_2_frame, f'outputs/tasks/{task_type}')\n",
    "G = obj_loc_2_frame.to_graph()\n",
    "obj_loc_2_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(f'outputs/tasks/{task_type}.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(n_tasks):\n",
    "    # Generate trial info\n",
    "    trials = env.generate_trials(tasks=[obj_loc_2_frame], mode='train')\n",
    "    imgs, _, info_dict = trials[0]\n",
    "\n",
    "    # Write trial to disk\n",
    "    read_write.write_trial(imgs, info_dict, f'outputs/{task_type}/trials/train' + f'/trial{i}')\n",
    "\n",
    "show_task_info(task_type, 0)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Obj Cat 1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whens = ['last0']\n",
    "obj_cat_1_frame = Base1FrameTask(whens, tg.GetCategory)\n",
    "task_type = \"obj_cat_1_frame \"\n",
    "\n",
    "read_write.write_task(obj_loc_1_frame, f'outputs/tasks/{task_type}')\n",
    "G = obj_cat_1_frame.to_graph()\n",
    "obj_cat_1_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(f'outputs/tasks/{task_type}.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "for i in range(n_tasks):\n",
    "    # Generate trial info\n",
    "    trials = env.generate_trials(tasks=[obj_cat_1_frame], mode='train')\n",
    "    imgs, _, info_dict = trials[0]\n",
    "\n",
    "    # Write trial to disk\n",
    "    read_write.write_trial(imgs, info_dict, f'outputs/{task_type}/trials/train' + f'/trial{i}')\n",
    "\n",
    "show_task_info(task_type, 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Obj Cat 2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whens = ['last0', 'last1']\n",
    "obj_cat_2_frame = Base2FrameTask(whens, tg.GetCategory)\n",
    "task_type = \"obj_cat_2_frame \"\n",
    "\n",
    "read_write.write_task(obj_cat_2_frame, f'outputs/tasks/{task_type}')\n",
    "G = obj_cat_2_frame.to_graph()\n",
    "obj_cat_2_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(f'outputs/tasks/{task_type}.png')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "for i in range(n_tasks):\n",
    "    # Generate trial info\n",
    "    trials = env.generate_trials(tasks=[obj_cat_2_frame], mode='train')\n",
    "    imgs, _, info_dict = trials[0]\n",
    "\n",
    "    # Write trial to disk\n",
    "    read_write.write_trial(imgs, info_dict, f'outputs/{task_type}/trials/train' + f'/trial{i}')\n",
    "\n",
    "show_task_info(task_type, 0)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Spatial Attn 1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whens = ['last0']\n",
    "obj_cat_1_frame = Base1FrameTask(whens, tg.GetCategory)\n",
    "task_type = \"Spatial_attn_1_frame\"\n",
    "\n",
    "read_write.write_task(obj_loc_1_frame, f'outputs/tasks/{task_type}')\n",
    "G = obj_cat_1_frame.to_graph()\n",
    "obj_cat_1_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(f'outputs/tasks/{task_type}.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for n_distractor_frame in range(1, 4):\n",
    "    for i in range(n_tasks):\n",
    "        # Generate trial info\n",
    "        #! TODO: more than one distractor in one frame\n",
    "        trials = env.generate_trials(tasks=[obj_cat_1_frame], mode='train', add_distractor_frame=n_distractor_frame)\n",
    "        imgs, _, info_dict = trials[0]\n",
    "        # Write trial to disk\n",
    "        read_write.write_trial(imgs, info_dict, f'outputs/{task_type}_{n_distractor_frame}/trials/train' + f'/trial{i}')\n",
    "    show_task_info(f\"{task_type}_{n_distractor_frame}\", 0)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Spatial Attn 2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whens = ['last0', 'last1']\n",
    "obj_cat_2_frame = Base2FrameTask(whens, tg.GetCategory)\n",
    "task_type = \"spatial_attn_2_frame \"\n",
    "\n",
    "read_write.write_task(obj_cat_2_frame, f'outputs/tasks/{task_type}')\n",
    "G = obj_cat_2_frame.to_graph()\n",
    "obj_cat_2_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(f'outputs/tasks/{task_type}.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for n_distractor_frame in range(1, 7):\n",
    "    for i in range(n_tasks):\n",
    "        # Generate trial info\n",
    "        #! TODO: more than one distractor in one frame\n",
    "        trials = env.generate_trials(tasks=[obj_cat_2_frame], mode='train', add_distractor_frame=n_distractor_frame)\n",
    "        imgs, _, info_dict = trials[0]\n",
    "        # Write trial to disk\n",
    "        read_write.write_trial(imgs, info_dict, f'outputs/{task_type}_{n_distractor_frame}/trials/train' + f'/trial{i}')\n",
    "    show_task_info(f\"{task_type}_{n_distractor_frame}\", 0)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Attn 1 Frame"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whens = ['last0']\n",
    "obj_loc_1_frame = Base1FrameTask(whens, tg.GetLoc)\n",
    "task_type = \"feature_attn_1_frame \"\n",
    "\n",
    "read_write.write_task(obj_loc_1_frame, f'outputs/tasks/{task_type}')\n",
    "G = obj_loc_1_frame.to_graph()\n",
    "obj_loc_1_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(f'outputs/tasks/{task_type}.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for n_distractor_frame in range(1, 4):\n",
    "    for i in range(n_tasks):\n",
    "        # Generate trial info\n",
    "        trials = env.generate_trials(tasks=[obj_loc_1_frame], mode='train', add_distractor_frame=n_distractor_frame)\n",
    "        imgs, _, info_dict = trials[0]\n",
    "\n",
    "        # Write trial to disk\n",
    "        read_write.write_trial(imgs, info_dict, f'outputs/{task_type}_{n_distractor_frame}/trials/train' + f'/trial{i}')\n",
    "\n",
    "    show_task_info(f\"{task_type}_{n_distractor_frame}\", 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Attn 2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whens = ['last0', 'last1']\n",
    "obj_loc_2_frame = Base2FrameTask(whens, tg.GetLoc)\n",
    "task_type = \"feature_attn_2_frame \"\n",
    "\n",
    "read_write.write_task(obj_loc_2_frame, f'outputs/tasks/{task_type}')\n",
    "G = obj_loc_2_frame.to_graph()\n",
    "obj_loc_2_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(f'outputs/tasks/{task_type}.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for n_distractor_frame in range(1, 7):\n",
    "    for i in range(n_tasks):\n",
    "        # Generate trial info\n",
    "        trials = env.generate_trials(tasks=[obj_loc_2_frame], mode='train', add_distractor_frame=n_distractor_frame)\n",
    "        imgs, _, info_dict = trials[0]\n",
    "\n",
    "        # Write trial to disk\n",
    "        read_write.write_trial(imgs, info_dict, f'outputs/{task_type}_{n_distractor_frame}/trials/train' + f'/trial{i}')\n",
    "\n",
    "    show_task_info(f\"{task_type}_{n_distractor_frame}\", 0)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Temporal Attention 1 Frame"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for op, name_op in zip([tg.GetLoc, tg.GetCategory], ['loc', 'cat']):\n",
    "    for n_distractor_time in range(1, 12):\n",
    "        whens = [f'last{n_distractor_time}']\n",
    "        obj_loc_1_frame = Base1FrameTask(whens, op)\n",
    "        task_type = f\"temporal_attn_1_frame_{n_distractor_time}_{name_op}\"\n",
    "\n",
    "        read_write.write_task(obj_loc_1_frame, f'outputs/tasks/{task_type}')\n",
    "        G = obj_loc_1_frame.to_graph()\n",
    "        obj_loc_1_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "        for i in range(n_tasks):\n",
    "            # Generate trial info\n",
    "            trials = env.generate_trials(tasks=[obj_loc_1_frame], mode='train', add_distractor_time=n_distractor_time)\n",
    "            imgs, _, info_dict = trials[0]\n",
    "\n",
    "            # Write trial to disk\n",
    "            read_write.write_trial(imgs, info_dict, f'outputs/{task_type}/trials/train' + f'/trial{i}')\n",
    "\n",
    "        show_task_info(task_type, 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Temporal Attention 2 Frame"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for op, name_op in zip([tg.GetLoc, tg.GetCategory], ['loc', 'cat']):\n",
    "    for n_distractor_time in range(1, 12):\n",
    "        whens = ['last0', f'last{n_distractor_time + 1}']\n",
    "        obj_loc_2_frame = Base2FrameTask(whens, op)\n",
    "        task_type = f\"temporal_attn_2_frame_{n_distractor_time}_{name_op}\"\n",
    "\n",
    "        read_write.write_task(obj_loc_2_frame, f'outputs/tasks/{task_type}')\n",
    "        G = obj_loc_2_frame.to_graph()\n",
    "        obj_loc_2_frame.draw_graph(f'outputs/tasks/{task_type}.png', G)\n",
    "\n",
    "        for i in range(n_tasks):\n",
    "            # Generate trial info\n",
    "            trials = env.generate_trials(tasks=[obj_loc_2_frame], mode='train', add_distractor_time=n_distractor_time)\n",
    "            imgs, _, info_dict = trials[0]\n",
    "\n",
    "            # Write trial to disk\n",
    "            read_write.write_trial(imgs, info_dict, f'outputs/{task_type}/trials/train' + f'/trial{i}')\n",
    "\n",
    "        show_task_info(task_type, 0)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bashlab_cogenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
